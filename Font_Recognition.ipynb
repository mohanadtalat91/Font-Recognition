{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "iRWhpD4qyDdG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hUkBRdY8ndhZ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pylab as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from PIL import ImageFilter\n",
        "import cv2\n",
        "import itertools\n",
        "import random\n",
        "import keras\n",
        "import imutils\n",
        "from imutils import paths\n",
        "import os\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "\n",
        "tpu_address = TF_MASTER"
      ],
      "metadata": {
        "id": "qkbA_iB9XL-X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "print(\"Number of devices: \", len(tf.config.list_logical_devices('TPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qgw10dCXS3k",
        "outputId": "802d498c-7c47-42c4-9080-0811f23f3eeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
            "Number of devices:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "Y9KCHCf3XjVZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TbCBRSGwbke",
        "outputId": "3770ae51-8f9c-4190-ddb1-cb4c3ebd8e9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JHEynQv2ndhn"
      },
      "outputs": [],
      "source": [
        "def pil_image(img_path):\n",
        "    pil_im =PIL.Image.open(img_path).convert('L')\n",
        "    pil_im=pil_im.resize((105,105))\n",
        "    #imshow(np.asarray(pil_im))\n",
        "    return pil_im"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hbTCU2qndht"
      },
      "source": [
        "# Augumentation Steps \n",
        "\n",
        "* Noise\n",
        "\n",
        "* Blur\n",
        "\n",
        "* Perpective Rotation\n",
        "\n",
        "* Shading\n",
        "\n",
        "*  Variable Character Spacing\n",
        "\n",
        "*  Variable Aspect Ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQevV_gkwIHS"
      },
      "source": [
        "## Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MLCHbBKsndhv"
      },
      "outputs": [],
      "source": [
        "def noise_image(pil_im):\n",
        "    # Adding Noise to image\n",
        "    img_array = np.asarray(pil_im)\n",
        "    mean = 0.0   # some constant\n",
        "    std = 5   # some constant (standard deviation)\n",
        "    noisy_img = img_array + np.random.normal(mean, std, img_array.shape)\n",
        "    noisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
        "    noise_img = PIL.Image.fromarray(np.uint8(noisy_img_clipped)) # output\n",
        "    #imshow((noisy_img_clipped ).astype(np.uint8))\n",
        "    noise_img=noise_img.resize((105,105))\n",
        "    return noise_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5TPvDBV5ndh2"
      },
      "outputs": [],
      "source": [
        "def blur_image(pil_im):\n",
        "    #Adding Blur to image \n",
        "    blur_img = pil_im.filter(ImageFilter.GaussianBlur(radius=3)) # ouput\n",
        "    #imshow(blur_img)\n",
        "    blur_img=blur_img.resize((105,105))\n",
        "    return blur_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CIDSvv7Qndh6"
      },
      "outputs": [],
      "source": [
        "def affine_rotation(img):\n",
        "    \n",
        "    #img=cv2.imread(img_path,0)\n",
        "    rows, columns = img.shape\n",
        "\n",
        "    point1 = np.float32([[10, 10], [30, 10], [10, 30]])\n",
        "    point2 = np.float32([[20, 15], [40, 10], [20, 40]])\n",
        "\n",
        "    A = cv2.getAffineTransform(point1, point2)\n",
        "\n",
        "    output = cv2.warpAffine(img, A, (columns, rows))\n",
        "    affine_img = PIL.Image.fromarray(np.uint8(output)) # affine rotated output\n",
        "    #imshow(output)\n",
        "    affine_img=affine_img.resize((105,105))\n",
        "    return affine_img\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VCy6ReUNndh_"
      },
      "outputs": [],
      "source": [
        "def gradient_fill(image):\n",
        "    #image=cv2.imread(img_path,0)\n",
        "    laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
        "    laplacian = cv2.resize(laplacian, (105, 105))\n",
        "    return laplacian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBLjVHT9ndiF"
      },
      "source": [
        "## Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6hc1RAaVndiI"
      },
      "outputs": [],
      "source": [
        "data_path = \"drive/MyDrive/font_patch/\"\n",
        "data=[]\n",
        "labels=[]\n",
        "imagePaths = sorted(list(paths.list_images(data_path)))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HYYzr_c1ndiN"
      },
      "outputs": [],
      "source": [
        "def conv_label(label):\n",
        "    if label == 'Lato':\n",
        "        return 0\n",
        "    elif label == 'Raleway':\n",
        "        return 1\n",
        "    elif label == 'Roboto':\n",
        "        return 2\n",
        "    elif label == 'Sansation':\n",
        "        return 3\n",
        "    elif label == 'Walkway':\n",
        "        return 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5emmKqjd-3Q",
        "outputId": "92e29eb0-2f48-4675-b816-544ace1808b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['blur', 'noise', 'affine', 'gradient']\n"
          ]
        }
      ],
      "source": [
        "augument=[\"blur\",\"noise\",\"affine\",\"gradient\"]\n",
        "a=itertools.combinations(augument, 4)\n",
        "\n",
        "for i in list(a): \n",
        "    print(list(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIc22kLf4SAP",
        "outputId": "bc2adc16-346c-4911-ac70-13210ad0336e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "counter=0\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    label = conv_label(label)\n",
        "    pil_img = pil_image(imagePath)\n",
        "    #imshow(pil_img)\n",
        "    \n",
        "    # Adding original image\n",
        "    org_img = img_to_array(pil_img)\n",
        "    #print(org_img.shape)\n",
        "    data.append(org_img)\n",
        "    labels.append(label)\n",
        "    \n",
        "    augument=[\"noise\",\"blur\",\"affine\",\"gradient\"]\n",
        "    for l in range(0,len(augument)):\n",
        "    \n",
        "        a=itertools.combinations(augument, l+1)\n",
        "\n",
        "        for i in list(a): \n",
        "            combinations=list(i)\n",
        "            print(len(combinations))\n",
        "            temp_img = pil_img\n",
        "            for j in combinations:\n",
        "            \n",
        "                if j == 'noise':\n",
        "                    # Adding Noise image\n",
        "                    temp_img = noise_image(temp_img)\n",
        "                    \n",
        "                elif j == 'blur':\n",
        "                    # Adding Blur image\n",
        "                    temp_img = blur_image(temp_img)\n",
        "                    #imshow(blur_img)\n",
        "                    \n",
        "    \n",
        "                elif j == 'affine':\n",
        "                    open_cv_affine = np.array(pil_img)\n",
        "                    # Adding affine rotation image\n",
        "                    temp_img = affine_rotation(open_cv_affine)\n",
        "\n",
        "                elif j == 'gradient':\n",
        "                    open_cv_gradient = np.array(pil_img)\n",
        "                    # Adding gradient image\n",
        "                    temp_img = gradient_fill(open_cv_gradient)\n",
        "  \n",
        "            temp_img = img_to_array(temp_img)\n",
        "            data.append(temp_img)\n",
        "            labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFpIsgdHndit",
        "outputId": "096c2368-6e04-4819-dc9f-5e559a2668ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ],
      "source": [
        "data = np.asarray(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "print(\"Success\")\n",
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yptdjjt4wIHZ",
        "outputId": "95c323c2-4850-42ef-ea81-a270b789e615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(468, 105, 105, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "trainX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVliZXC0wIHZ",
        "outputId": "a4c9af19-201d-4d3e-9e0a-cb1828fd9a4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(468,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "trainY.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnotDtkhwIHa",
        "outputId": "f7fedea9-cbb6-4829-cf48-1e7e2408482d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156, 105, 105, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "testX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFJyXkLqwIHa",
        "outputId": "3a3baee5-536f-41c6-eff5-b439d7d8ac22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "testY.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1NQr6OCQ_3qO"
      },
      "outputs": [],
      "source": [
        "# convert the labels from integers to vectors\n",
        "\n",
        "trainY = to_categorical(trainY, num_classes=5)\n",
        "testY = to_categorical(testY, num_classes=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9omeq7fqryGW"
      },
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-vWihISP8kHV",
        "outputId": "95411e0e-bcf9-44aa-9bf6-d9482b0e3b5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'channels_last'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "K.image_data_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DpDdwzQguqWR"
      },
      "outputs": [],
      "source": [
        " def create_model():\n",
        "  model=Sequential()\n",
        "\n",
        "  # Cu Layers \n",
        "  model.add(Conv2D(64, kernel_size=(48, 48), activation='relu', input_shape=(105,105,1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=(24, 24), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2DTranspose(128, (24,24), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
        "  model.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2DTranspose(64, (12,12), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
        "  model.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "  #Cs Layers\n",
        "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
        "\n",
        "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
        "\n",
        "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(4096,activation='relu'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(2383,activation='relu'))\n",
        "\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        " \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LSUkpdoI2J-M"
      },
      "outputs": [],
      "source": [
        "#with strategy.scope():\n",
        "#  batch_size = 128\n",
        "#  epochs = 50\n",
        "#  model= create_model()\n",
        "#  sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#  model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IH8DclwlLkOw"
      },
      "outputs": [],
      "source": [
        "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "\n",
        "filepath=\"top_model.h5\"\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "callbacks_list = [early_stopping,checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZfjlSwNt73XO",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab73d80-644b-4182-d45b-d3ddd82357ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1594 - accuracy: 0.2735\n",
            "Epoch 1: val_loss improved from inf to 0.15811, saving model to top_model.h5\n",
            "4/4 [==============================] - 25s 6s/step - loss: 0.1594 - accuracy: 0.2735 - val_loss: 0.1581 - val_accuracy: 0.4167\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.3761\n",
            "Epoch 2: val_loss improved from 0.15811 to 0.15765, saving model to top_model.h5\n",
            "4/4 [==============================] - 27s 7s/step - loss: 0.1486 - accuracy: 0.3761 - val_loss: 0.1576 - val_accuracy: 0.4167\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.3889\n",
            "Epoch 3: val_loss improved from 0.15765 to 0.15685, saving model to top_model.h5\n",
            "4/4 [==============================] - 24s 6s/step - loss: 0.1439 - accuracy: 0.3889 - val_loss: 0.1568 - val_accuracy: 0.4167\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.4402\n",
            "Epoch 4: val_loss improved from 0.15685 to 0.15677, saving model to top_model.h5\n",
            "4/4 [==============================] - 18s 5s/step - loss: 0.1354 - accuracy: 0.4402 - val_loss: 0.1568 - val_accuracy: 0.4295\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.4957\n",
            "Epoch 5: val_loss improved from 0.15677 to 0.15672, saving model to top_model.h5\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.1259 - accuracy: 0.4957 - val_loss: 0.1567 - val_accuracy: 0.5705\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.5641\n",
            "Epoch 6: val_loss improved from 0.15672 to 0.15615, saving model to top_model.h5\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.1121 - accuracy: 0.5641 - val_loss: 0.1561 - val_accuracy: 0.5449\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.5897\n",
            "Epoch 7: val_loss did not improve from 0.15615\n",
            "4/4 [==============================] - 1s 340ms/step - loss: 0.1002 - accuracy: 0.5897 - val_loss: 0.1574 - val_accuracy: 0.3590\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.6560\n",
            "Epoch 8: val_loss did not improve from 0.15615\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.0898 - accuracy: 0.6560 - val_loss: 0.1583 - val_accuracy: 0.3141\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.7179\n",
            "Epoch 9: val_loss did not improve from 0.15615\n",
            "4/4 [==============================] - 1s 339ms/step - loss: 0.0755 - accuracy: 0.7179 - val_loss: 0.1573 - val_accuracy: 0.6410\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.7650\n",
            "Epoch 10: val_loss did not improve from 0.15615\n",
            "4/4 [==============================] - 1s 333ms/step - loss: 0.0662 - accuracy: 0.7650 - val_loss: 0.1579 - val_accuracy: 0.2692\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.7714\n",
            "Epoch 11: val_loss did not improve from 0.15615\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.1631 - val_accuracy: 0.2821\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.7179\n",
            "Epoch 12: val_loss did not improve from 0.15615\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.0714 - accuracy: 0.7179 - val_loss: 0.1633 - val_accuracy: 0.2500\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.7585\n",
            "Epoch 13: val_loss improved from 0.15615 to 0.15118, saving model to top_model.h5\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0647 - accuracy: 0.7585 - val_loss: 0.1512 - val_accuracy: 0.7179\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.7927\n",
            "Epoch 14: val_loss improved from 0.15118 to 0.14825, saving model to top_model.h5\n",
            "4/4 [==============================] - 17s 4s/step - loss: 0.0568 - accuracy: 0.7927 - val_loss: 0.1483 - val_accuracy: 0.5897\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.7799\n",
            "Epoch 15: val_loss improved from 0.14825 to 0.14541, saving model to top_model.h5\n",
            "4/4 [==============================] - 17s 4s/step - loss: 0.0586 - accuracy: 0.7799 - val_loss: 0.1454 - val_accuracy: 0.4615\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.8184\n",
            "Epoch 16: val_loss did not improve from 0.14541\n",
            "4/4 [==============================] - 1s 331ms/step - loss: 0.0491 - accuracy: 0.8184 - val_loss: 0.1457 - val_accuracy: 0.6987\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.8269\n",
            "Epoch 17: val_loss did not improve from 0.14541\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.0494 - accuracy: 0.8269 - val_loss: 0.1500 - val_accuracy: 0.5321\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.8205\n",
            "Epoch 18: val_loss improved from 0.14541 to 0.13706, saving model to top_model.h5\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0475 - accuracy: 0.8205 - val_loss: 0.1371 - val_accuracy: 0.6474\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.8483\n",
            "Epoch 19: val_loss improved from 0.13706 to 0.13549, saving model to top_model.h5\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0448 - accuracy: 0.8483 - val_loss: 0.1355 - val_accuracy: 0.6410\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.8269\n",
            "Epoch 20: val_loss did not improve from 0.13549\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.0416 - accuracy: 0.8269 - val_loss: 0.1420 - val_accuracy: 0.5705\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.8547\n",
            "Epoch 21: val_loss improved from 0.13549 to 0.13112, saving model to top_model.h5\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0417 - accuracy: 0.8547 - val_loss: 0.1311 - val_accuracy: 0.5513\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.8718\n",
            "Epoch 22: val_loss did not improve from 0.13112\n",
            "4/4 [==============================] - 1s 331ms/step - loss: 0.0334 - accuracy: 0.8718 - val_loss: 0.1391 - val_accuracy: 0.5833\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.8932\n",
            "Epoch 23: val_loss improved from 0.13112 to 0.12753, saving model to top_model.h5\n",
            "4/4 [==============================] - 14s 4s/step - loss: 0.0313 - accuracy: 0.8932 - val_loss: 0.1275 - val_accuracy: 0.6346\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9017\n",
            "Epoch 24: val_loss did not improve from 0.12753\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.0284 - accuracy: 0.9017 - val_loss: 0.1439 - val_accuracy: 0.5256\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9295\n",
            "Epoch 25: val_loss did not improve from 0.12753\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.0214 - accuracy: 0.9295 - val_loss: 0.1655 - val_accuracy: 0.4744\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.8846\n",
            "Epoch 26: val_loss improved from 0.12753 to 0.12272, saving model to top_model.h5\n",
            "4/4 [==============================] - 14s 4s/step - loss: 0.0301 - accuracy: 0.8846 - val_loss: 0.1227 - val_accuracy: 0.4872\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.8953\n",
            "Epoch 27: val_loss did not improve from 0.12272\n",
            "4/4 [==============================] - 1s 326ms/step - loss: 0.0298 - accuracy: 0.8953 - val_loss: 0.1396 - val_accuracy: 0.3654\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.8974\n",
            "Epoch 28: val_loss improved from 0.12272 to 0.12118, saving model to top_model.h5\n",
            "4/4 [==============================] - 14s 4s/step - loss: 0.0305 - accuracy: 0.8974 - val_loss: 0.1212 - val_accuracy: 0.5385\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9295\n",
            "Epoch 29: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 337ms/step - loss: 0.0244 - accuracy: 0.9295 - val_loss: 0.1281 - val_accuracy: 0.5449\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9402\n",
            "Epoch 30: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.0201 - accuracy: 0.9402 - val_loss: 0.1316 - val_accuracy: 0.5321\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9487\n",
            "Epoch 31: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 325ms/step - loss: 0.0164 - accuracy: 0.9487 - val_loss: 0.1585 - val_accuracy: 0.2756\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9658\n",
            "Epoch 32: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.0136 - accuracy: 0.9658 - val_loss: 0.1735 - val_accuracy: 0.2500\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9679\n",
            "Epoch 33: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.0116 - accuracy: 0.9679 - val_loss: 0.1329 - val_accuracy: 0.5449\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9915\n",
            "Epoch 34: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.0044 - accuracy: 0.9915 - val_loss: 0.1331 - val_accuracy: 0.4231\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9872\n",
            "Epoch 35: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 331ms/step - loss: 0.0046 - accuracy: 0.9872 - val_loss: 0.2084 - val_accuracy: 0.2436\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9936\n",
            "Epoch 36: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.0027 - accuracy: 0.9936 - val_loss: 0.1595 - val_accuracy: 0.2949\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9979\n",
            "Epoch 37: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 0.0019 - accuracy: 0.9979 - val_loss: 0.1216 - val_accuracy: 0.5256\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9872\n",
            "Epoch 38: val_loss did not improve from 0.12118\n",
            "4/4 [==============================] - 3s 726ms/step - loss: 0.0043 - accuracy: 0.9872 - val_loss: 0.1212 - val_accuracy: 0.4744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a625d0250>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  batch_size = 128\n",
        "  epochs = 50\n",
        "  model= create_model()\n",
        "  sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss='mean_squared_error', steps_per_execution = 50, optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "model.fit(trainX, trainY,shuffle=True,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(testX, testY),callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLtRqPzhLOUF",
        "outputId": "eb78310e-36ee-42fd-dd86-7ce2f6a16024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.12157919257879257\n",
            "Test accuracy: 0.4743589758872986\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9oDaZS8LuWem"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('top_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ltfB09zptlNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0603aa2-7cac-4dac-9512-c95140260215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.12064941972494125\n",
            "Test accuracy: 0.5384615659713745\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov6w2Kmdv4dV",
        "outputId": "310fd109-7f8f-4a21-dedd-45ad1715db12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(105, 105, 1)\n"
          ]
        }
      ],
      "source": [
        "img_path=\"drive/MyDrive/sample/sample.jpg\"\n",
        "pil_im =PIL.Image.open(img_path).convert('L')\n",
        "pil_im=pil_image(img_path)\n",
        "org_img = img_to_array(pil_im)\n",
        "print(org_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jN4su5FX3MzC"
      },
      "outputs": [],
      "source": [
        "def rev_conv_label(label):\n",
        "    if label == 0 :\n",
        "        return 'Lato'\n",
        "    elif label == 1:\n",
        "        return 'Raleway'\n",
        "    elif label == 2 :\n",
        "        return 'Roboto'\n",
        "    elif label == 3 :\n",
        "        return 'Sansation'\n",
        "    elif label == 4:\n",
        "        return 'Walkway'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "q1yBSPTh0ooD"
      },
      "outputs": [],
      "source": [
        "data=[]\n",
        "data.append(org_img)\n",
        "data = np.asarray(data, dtype=\"float\") / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR2YCKaaznhT",
        "outputId": "2d5e5f21-6ed2-42f6-d94c-c0879e394afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 384ms/step\n"
          ]
        }
      ],
      "source": [
        "y = model.predict(data)\n",
        "y = np.round(y).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "SQjS-Iv80iLc",
        "outputId": "2255ab70-785d-420c-a74e-d5806c6c688e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dedhd47n/Pw+qaNRMTSHmmfAilZiSGIqeaKvGRhpqqjHp7xKq59L+UcXFcVBDclVxajrkUKp0CjEHiSkkNQch5qG01PT8/tj7+66173evPb/vXjv7/lyX681ee+21nv2s7bnv5x5DjBHHcbqXRdo9AMdx2osvAo7T5SzW7gGIJZdc8vVPPvlklXaPoxpLLLHEGx9//PE32j0Ox2kVIS82gRBCzMtYKhFCIMYY2j0Ox2kVvh1wnC7HFwHH6XL6ZREIIewZQng6hPBcCOGU/riH4zitoeU2gRDCosAzwG7AfOBh4KAY45wqn3ObgOO0gf7wDmwHPBdjfAEghHAdMAbIXARWXHHF/P/fn6Knp6ejxus4ALNmzXo7xriSPd4fi8DqwCup1/OB7e1JIYQjgSMBBg8ezDvvvNMPQ+kfZs6c2e4hOE7dhBBeKne8bYbBGOOUGGNPjLFnpZX6LE6O4wwQ/bEIvAqsmXq9RvGY4zg5pD8WgYeB9UMIQ0IIiwMHArf0w30cx2kBLV8EYoyfA8cBfwbmAtfHGJ9q5T0GDRpU87nTp0/n/vvvb+XtHWehol9yB2KMtwG39ce162X69OkMGjSIHXbYod1DcZxcstBEDP7hD39g++23Z+jQoYwePZo33niDefPmcemll3Leeeex1VZbcc899zBv3jxGjhzJFltswahRo3j55ZfbPXTHaSsLzSIwYsQIZsyYwaOPPsqBBx7I2Wefzdprr83RRx/NhAkTeOyxx9hxxx05/vjjGTduHE888QSHHHIIJ5xwQruH7jhtJTepxM0yf/58DjjgABYsWMCnn37KkCFDyp73wAMPcOONNwIwduxYTj755IEcpuPkjoVGEzj++OM57rjjmD17NpMnT+aTTz5p95AcpyNYaBaBDz74gNVXXx2AK6+8svf40ksvzYcfftj7eocdduC6664D4Oqrr2bHHXcc2IE6Ts7IRVGRnp6eOGvWLGodyyKLLMJqq63W+3rixImsu+66TJgwgeWWW46RI0fy8MMPM336dJ555hn2228/FllkES688EIGDx7M+PHjefvtt1lppZW4/PLLGTx4cM1jLSYQ1f0dHafdhBBmxRh7+hzPww+63kWgnfgi4HQqWYvAQrMdcBynMXwRcJwuxxcBx+lyfBFwnC7HFwHH6XJ8EXCcLscXAcfpcnwRcJwuxxcBx+lyfBFwnC4nN6nEa621FiHkv6fHWmut1e4hOE5Lyc0iMG/evHYPwXG6Et8OOE6X44uA43Q5vgg4Tpfji4DjdDm+CDhOl+OLgON0Ob4IOE6X44uA43Q5vgg4Tpfji4DjdDm+CDhOl+OLgON0Ob4IOE6X44uA43Q5DS8CIYQ1Qwh3hhDmhBCeCiGcWDy+fAjhryGEZ4t/l2vdcB3HaTXNaAKfAz+JMW4CDAOODSFsApwCTIsxrg9MK752HCenNLwIxBgXxBgfKf77Q2AusDowBlBv8CuBfZsdpOM4/UdLbAIhhLWBocCDwCoxxgXFt14HVsn4zJEhhJkhhJlvvfVWK4bhOE4DNL0IhBAGAf8HnBRj/Ef6vVjo4V22j3eMcUqMsSfG2LPSSis1OwzHcRqkqUUghPAVCgvA1THGG4uH3wghrFp8f1XgzeaG6DhOf9KMdyAAlwFzY4z/lXrrFmBc8d/jgJsbH57jOP1NM9WGhwNjgdkhhMeKx34KnAlcH0I4HHgJ2L+5ITqO0580vAjEGO8FshoFjGr0uo7jDCweMeg4XU5umo/EGPnyyy8BMjsRVepQVGv3ooLDAj799FMAFl10UYDeey+22GKZ12u2Q5Lu8cUXX5Qct2NIH8tTVybNnf5mPS+NvRnstdNzU+6eiyySD3mmudEzts9R74tWPt/PP/8cSOai1jnJx8w5jtM2cqMJQLKSWUmi1bOcdKx3JdX5X/3qV4Fkxf7KV75Scp40hcUXX7yu61dC0ixLOqRX7jxpABYrnftDE9Bc6Dehe9g5y9s8aTzSKPU7ytJoKmmejd5bc1frHLkm4DhdTi40gRgjX3zxRa/U1epp9zR2P5Wm3pXUSuXPPvsMSDSDVmoAwo7x3//+N9BXC8kbmiv91XPQuK2No5VYqaZ72bnMi2Zg7T76Hen3ZX9X/WET0L2kZVTDNQHH6XJyoQmEEEr2kddeey0Ajz76KABf//rXATjmmGMAWG211XrPtRbrWldWq2VcddVVAMyZMweAo446CoD11luvjm9SGX1Hfb8ZM2YAsMwyywBw9NFH956b/o7t5oMPPgDg3HPPBZLvceyxxwKw8sor99u99Tx++9vfltx7/PjxAGyyySb9du9G0O/K2i4mT54MJN/Han+VtNxq6F7SMsaMGQPAiBEjahtzw3d2HGehIBeaABRWM+2npk+fDiQSUyvd2muvDcDhhx/e5/P1agI6/4033gDg4osvBmD27NkArLrqqgBMnDixru9RiXfffReAc845B4C5c+cCidSXdMsbH330EQBXXHEFAG+//TYAG264IQAHH3wwkOxFW2njePHFFwG46KKLgEQT2HXXXYH8aQJCv0PZff70pz8BcO+99wKJ1G5FfINsAZ988gkAG220EeCagOM4NZIbTSDG2LsqDh48GICll14aSLwF2kOX0wQajRd4/fXXgUTiaIV+5JFH6rpeLbz22mslf5dcckkA1lxzTSBfdoByLLvssgC88847ANx2221AognUao2uB11zueUKpSqlwfXHvVqB9V5Ic7GeFP21cQONoP9vvva1rwFJDEzNn296BI7jdDS5XE6/8Y1vAMleVNL5n//8J1BqSS0XbVcPCxYs6HNNAJU80z4Xmt/rvv/++0Cy+uv7DRo0CCiVbjb2vJ1Iqv3jH4XCUUsssQSQ2E80h7KjtBLtdz/++OOSsbRCgvYHWdGuVlPNinNoBM2RNGa9rhXXBByny8mNJpBeGVVzUHsbrfrav6elc7OS8tVXXwX6xnjLa/Dhhx/2nrv88ss3dS/ZAt577z0gGbskaPq7NCMZWo3GIo1MWsorr7wCwFNPPQX0jyaQ9XzzkjWYhc1S1ZzZ/Bj7txnqzR7s/VzTd3Ycp6PJjSbw5Zdf9q5gspZLE5D/U/t0vYYkmrBR5s2bByQrtfblsj9oHw+JJmAtwHbltdl1+ivJqfN1HdlA8kpWtqM0sgceeACA0aNHl3zORnO2Unq3O0egGlk5Avp99YetR9qHYhNqxTUBx+lyfBFwnC4nN9uBNEqokUol95Bcagq/hea3AzI22tRiucMUGAOwzjrrAH3VfEvW+7qWNbQpOKrcNTqBhx56COibGp21XeomrIvQpmHvu2+hS5+CoRpxfeqaMjpuvvnmdX2+e5+O4zhATjWBFVdcEUg0AkllGevkYoMkqahetOLKRWgDgWR8lKaQppomYO8hSah76bWMROUMg3kpklEJjV8p3y+99BIAG2ywQdvGlHespFfK+tChQ4HmCrRYA6yXF3McpyZyowmkVytpANII5s+fDyR7TqWyNsO//vUvAN58s9AqUZqAdd9JeteDDfTRXk33kgSVTUDfs9PQXKnoiBK8rCZgNaJuolIxWeibCNVMkJi1DdQaiNR9T8VxnBJyqQlIQq6wwgpA3/RLaQZp6t1DK/DIWuyFVlPtc+u5ly2RLq1Dtgy9v9RSSwFJmHSaPNsCbBKPnouKwRx66KFAMod5TfttB7ZYq7URtEJbqtVm1XvPpu/oOE5Hk+slWlZzmxqp5J5mkFRWDILVNrRSK9Q3TbXV2q7ASkJSCLLuoSId+psmz94BW9jDegk0t7LtdDN2rqq12mtluTHdq1r5fNcEHKfLyZUmYKWfIunsHqeS775WZPW3TSG0EmsVlUU/fW614iJZkYKKeBSyBagsVLliKXnWBGTzkJTTc3niiScA2HnnnUvOz+N3GSiykspaUVzEzm+9NhjXBByny2laEwghLArMBF6NMe4TQhgCXAesAMwCxsYYP23k2oqntsUs0tK50VbPKvAhm4B89dqfq/CovAjQeNswRTza9lBKTS5XGDLPPnWNTfMhjUDxAkotlibQzVhPirUNtKJVub2H1QwGImLwRGBu6vVZwHkxxvWA94C+pYEdx8kNTWkCIYQ1gL2BXwITQ2HJGQkcXDzlSuDnwCU1Xq/k9VprrVVyXBJIhS0hkUYqfmmx/lhJLe1f9VoawPrrrw/Ayy+/DJRmEcqOoKYbtX4PxTVI69CYZBOoZ/W3e0v7vYS0Dntt2yar0rhFlk97jTXWABKtSte+8847ATj55JMrXnegyGpVlxXFl7V/r0V6W3uJvedANG+t+3NN3ve/gZMB/TpWAN6PMcqnNx9YvdwHQwhHhhBmhhBmplVux3EGloY1gRDCPsCbMcZZIYRd6v18jHEKMAWgp6enrEnU7pmVRagIPKiuCaTGW/Ja0lnZgvJpKyuxXKkm7e1T36HstS2qf2D9t6uvXnZ9LMFKDivJJXFsvLjsFlZqWamYlu76bK3ZkT09PQBMmzatZKzPP/88kNhVVIehXVjJbsu5633NoW0UYmsAiHJSPQ8l4uulme3AcOA/Qgh7AUsAXwfOB5YNISxW1AbWAOrPwHEcZ8BoeBGIMZ4KnApQ1AT+X4zxkBDCDcB+FDwE44CbG72H9syKsZcGkK4sJOmcFZ2WVRxTHgZJB3kHlAGn4+mipuXiEyrdU9eQLcFKJBVUreUadr+XVezUSi+9ljZVyU9d695d11x33XWBxH4ir4AiOh977LGS8waStAZkYz9svr2OWw2gWoZfuWeTp6YxtdIffqhJFIyEz1GwEVzWD/dwHKdFtCRiMMY4HZhe/PcLwHatuK4s9pLy5SLvFKdeSaqm0R7f5varGaiiFCU5041ObB5BrZJTmoDO17WVJVkOK6mzGl0qy/Hxxx8HEqm01VZbAYndQftd+/k0teb961qywwwbNgyA++67r+S8e+65B4Dvfe97mdfqr2jC9PVsfIZtq3b//fcDSW6HqvzIPmSb4FhvQdpuVC1OP4/kNyLFcZwBIVe5AxbF1MtL8MwzzwCl+/S0faAcVsJotZd3QKu5NAlJTq3o6Xul4xPquacqIem4JGgtTUc0Prtvvfnmgqnlpz/9KZBoKZKsm266KQDnnHMOAN/85jdL3q9l3NWQZNW19bwkeaUZaM7LZUv2F+nMU6tVzZ1biG2bNGkSAPfeey+QzK2e/WmnnQbA4YcfXvK+kHamFvOdimsCjtPl5FoT0Iq88sorA31z/qG6dM7K6LMNSNVMU/fSPjAtOW29wWr7WUUI2upFkhy1aAK6tqTQgw8+CCTRePKYSLvQ3MyZMweAY445BoCpU6cCSRSmahyk9//ywtSaJSmJv8022wCJ7UaazwsvvADA008/DcD222+fea1Wk7bsa95lA5g4cSKQeDM0Bu3t9fqMM84AEu1w9913LznPxlxA8hyqxa3kCdcEHKfL8UXAcbqcXG8HhNx3UtPSRp9qJcGzAnesaq57yAipv+m0ZW09ai2gqdTadBISJIFJSy+9dMXPp8ctt+gvf/lLIEnasQErcv1JHZXBcI899igZs85Lu7ekJp9wwglVxwXJlkpzt8UWWwBwxx13lFz77rvvBspvBwYCzdFFF10EJK5LbfmsC1Dj1pyPHTsWSILXNNfaiu24446997r66qv76Vv0H64JOE6X0xGagKSypFjaMFitEYnVBBTSat1Wks4yRuqeacOV7iUJUK0ZqgyDMsLpWpIolQJL7LhnzZoFwMMPP1zyWUl0Gen0Ob2W1NL3tUFCSspKf7YatnimkES8/fbbgUTCypjZLqTByThqm3JoDmwasC37pmxXG4KeDijLSu3OM64JOE6Xk0tNIKvgaLnV1boIqyXeKM1Vx7Uvl2vQ3lMhpZBoAgpQqqYJKLFGAUe6p/bQlTQB6zpTcJCkltx4tnhIVlNKYdOF6y2Vlv6sHePw4cOBRNORxqREonTTGBUkaVXCTaUmHrIBPPvssyXv2fJoNkTbhlpnlQ1Pa6b292afS39qCFnlzL0hqeM4FcmlJmBXLklOrbjpPZjSe7PSRK1klFVdq7z2/oMGDSq5Z7lAHtsavVpbdNtsRH8rJQ5ZZKGWNE1b8wH22WcfAH71q18BicX+Zz/7GQC33XYbkEh8vS/SmoCdgyys3UFstNFGQKJVPffcc0AyD7JrQKIJtCpYqNJ11CjV7tc13rPOOguAjTfeGIDLL78cgLPPPhvoWwxGnhf9pvQbKjcO+/vTtbLKvDXTkNRqaLVeyzUBx+lycqkJ2H29pLKstbK2Q+LHl5S2vne7b5PmoOOrrLIK0FcKKrw2vcfT3l6xBko5zcJqHbpnLWXFhO6lpBfFNUhqKUFIYc+6xwUXXAAkdgl9XlJQ19l6661776VYgkZRiXjFA/z9738Hku+v+AGAMWPGAK0rrW4lalpLkXfCSsgzzzwTSEqjS9JPmDABSMqjXXHFFUDiSZI2pWIp+i6VyNJQW1FyXFi7iDckdRynJnKpCVi055IvP53eqz2z/mZpAtIUFL0nS6/2r9bnLcma3jNr1a4WpSikdUgLkTdA164FpU9bX7akj+wlQveShrP33nsDMHv2bCCZj9NPPx2AH/7wh72frVcqZ0VM7rrrrgBcc801JWOeOXNm7znysEh7aNY2YLXHdCk4xYZobnbbbTcgSYGW1iBJqviGgw46CIAbb7wRSH5jar0uTSLtJbKt6myUa5bXRlhpXg+Nxii4JuA4XU4uNQErFWQLkJRPW7i1OsuHnyVlFccvCaSVOCudV8fTLcIUAai9fjVkr7Alq+VHrwX5tiVhNAc77bRTybWzpMDo0aMBOO+884Bk7qQBpTWdeqVQljSTnUEanLwDSi2GJKchbVlvJelnpOcmKbzDDjsA5du/QTJHm2yyCZDYh+Td0JilAaRzWapJYesVyGp8Ug/VvAIeJ+A4TkVyqQkI7eEk/bTyplc6+c1tpp5F0kieBV1bkYEW7amlhUBSlMIWHLVofNqLCvmXZduoBWkTGq80nfXWW6/kPFvoQ/t1xTJI8itiUn+bIUvCqNmIJKmyCNNeHUXxbbnllk2PoxzpsnPSFqX1qAirkI3JRg5KY1NrOrVcf+SRR4C+TUYhe+9vi5Pa80UjtpFmi7W6JuA4XU6uNQG7f1KUWXrl1cpqpa5FOQba72k/qP2eRT7hdHFM7TN1ray4d1nybYMTaTT1aALSPnQNlQDTX0l+235M86L4B2kC8n2n6yQ0ipU8dj7kf1chz7QGp9Zlxx13XNPjSF/blhOH5JnrWUrLE7aegN1TqwitbTtW7vxqNSasDWDy5MlA4iWpxyagc6WxqA5Elq0jc0x1ne04zkJHLjWBLKuz9YlDsqeyks1KKUXOSSpIQlqprNVeElUrNCQSTvYFWZ1ttKHsFPJIaCw6T1K8FnQvrfoar1Z723jUSmPFJuivNId0HQFR657S2h+E1Yi2267Qg0bRiZovSKIJpV2Ve7bNkP5+miPNmZ3/apmMabsQJHUF9P3TktdWnbIWezt3N9xwQ8V7V0LXkH1o/PjxfcZTC64JOE6Xk0tNIMvfafdyaawmYFd3RZBp9ZRktHECVmqn25s99NBDQBKToGxCqwnIMi1NQGjvJttALVZda2XWZ+3ePyvHX+dJmul8W4mo2jjSZOXG2+e14YYbAok9Qi3TIPGwqFJSLfH3tYxJpGNJbNs0Kymz6gnouJ6v/b46L73Pt3t++4xtO7l6IwcrRXVmNVD1OAHHcSqSS00gC2kC5fyytsKQXf1svL+uld7zl/tcOvdf0sXmIdhmqNrHy/+sVV33rMefm9WSXN/bSicrYaxF27bpTo+lVc1BdR3t85VtqfoCkGgoalUmTUBz3Gxjz3QkpH4vthaDpZxkh75zaX37lbDxAXpetv6FfU5ZGkL6uK5RrUZBNVwTcJwuJ5eaQDXvQFr6qY6drMxZddYUt65r24jArBj8dPUg2wNA2oeNQFPMgjQBXdtqDLVIXtsnQN/XknUNHZeEtZpALdeoF/v8Ro0aBcBNN93Ue0w2CbUCs7aaZkn/RmzuvtUIsiz6dqzCVnquh6z5r7cuYC14PQHHcWqiKU0ghLAs8BtgMyAChwFPA/8LrA3MA/aPMb7X1CiLyLqebvZo6/7ZCkOKV7cZfba6cJY1Nh1RqPtKqqZz1tNIE7BahfWF16IJ2PoI+j42RyAL+eZtJp21hbQS+32UtZe2r8ieMm/ePACefPJJoHq1plrvmfbt25qIVpvK8nJYzU+vde1qc5++lr2HnkOW9lELuna9cQGWZjWB84E/xRg3ArYE5gKnANNijOsD04qvHcfJKQ0vAiGEZYCdgMsAYoyfxhjfB8YAVxZPuxLYt9lBOo7TfzSzHRgCvAVcHkLYEpgFnAisEmOUv+51IDvCJ4OsQAqpsOmkHqlqUpOl6kmNVsCOVelsCnFW2ad0ARCpbtoOSJW1yB2p7YDcVVkFTCqhAhZyIcn9qO2PjFTWPaTvoW2AEmp0PCuFupVozEr8UkouJM9F30euwlZtB9LPzbYbU9iv/WzWFktGZ83dMsssAzTWuEVzIhV+zz33BBpLINK19LtqtLFJM9uBxYCtgUtijEOBf2JU/1iYtbKm/hDCkSGEmSGEmfahOI4zcDSjCcwH5scY1W1yKoVF4I0QwqoxxgUhhFWBsjmrMcYpwBSAnp6emrokqKhIurCjVkOF8krCyAUoA5Q0Ba2Wkk4iq924DIiQJMJYt6TFuiu16tvSZ7UYg2yTDi2Y+itjY1ZJKWkl+lvJMNjqYCGheVNhT0jSi4XavTWaWmzHnE4M0/3125gzZw4AI0eOBPoacDV+PWeVeNPxegrFWsOzDRv+yU9+AiTFVao9g3Lu8yy3eK00rAnEGF8HXgkhbFg8NAqYA9wCjCseGwfc3Og9HMfpf5oNFjoeuDqEsDjwAjCewsJyfQjhcOAlYP8m79GLXHRp6SwJrlVbbrsNNtgASAJ6tDfWHtq66+yKrdfpQpjaZ0rrsHt/SVmNQau2XEo2bbmWlVtJONJ+JM20h64mQRSMY1uxl2uh1uqWYDYRR65CSJ6lnp9Kd+l51SNty5H+jehamjtpIUcccQSQPDebli2NQZqAfjsqm9YImhvbHl1YTcFSThPIKlpaq2bX1CIQY3wM6Cnz1qhmrus4zsCRy7BhYaWzVrq0lNAeXn9tSrH2zlphJYFsqWutyDrPlueCRBN46qmngGx7gzQFSRZdw6Yc17JSK1hJe3jZG9Sq/LDDDiv5XkKajxpnaCwK2JGmVO94KqHPZ9lXNttss95/y9YhD4u0KgUN1asJWAmZ1rqk9agVm7QoSXiNy2out99+O5B4ljTH0s7qGZd+u9YLZRvEVksCqtRktFHbgIcNO06Xk2tNQNi9Trqhp1Zvrai29LhKa0s6KX7AFijJCu9MIylqy4wpIUXSNl1aGxKpVC1tuRza22ofKi1DBU7UCuvUU08tGZsalT7++OMl1+vp6Sm5br3jqYQ+n5UElPbIbLPNNkCiCWgO77rrLiBpFWbjHrKKalRKwBkxYgSQFDfVc/v5z38OwCWXXAIkmp5Kfl122WVA8lz1u0trNLViE9SymsVUawXXKrtNyT1bfkXHcTqKjtAELOn9nvadivaaP39+ybmSnELW8UYSaOw+VdZmeQMUSaY9pMake9WTJmuTQ771rW8B8Oc//xlIimVeeumlANx5551AovEodVpj0TzJNz6QlLM1qI2abBaamxkzZgDZBTwaadOl+ARrN5FtQHOiyDvZCqQxSMuUFqXzWhVX0W5cE3CcLqcjNYH03lISTpLDlhFTQUtJFGkRNkW3FlQURPs426BUY7B5Co2U07YtrXfffXcAhgwZAiT+dBUukcdCElV7bGknsgHssccedY+lWcpJSklVxVAorl/fQ7Yc2+K73mKoAJtvvjmQaB+33HILkGhT8iipMYs0Bs2lxnDIIYfUNYZOwTUBx+lyOlITSO/NtUpL8ilbTvt1GzdgS5RV8rtapAlI+9D+VHtHK4U1tkql0rOwzS7XXXddAPbdt5CZff755wOJpBeKnJQtQVrJSSedBDSWydgfKP5BjTPU9lvjV9NPaW5ZUXFZpKW1tL4f/OAHANxxxx1A3z297EWyAeg57r333gAMGzYM6Bu30uksHN/CcZyG6UhNIG3Z1/5NGoC8AdIAdFxSOasBaS37PEklSWftY20OgS0f3YhNwJbEkm1AfnVJeklO22pLx7/zne8ASbaartdILnyj2EhCSDSYXXbZBYCZM2cCyRwqvn+vvfYqOd4MsjNI0ttycZoz/RYUaThp0iSgbzsy9w44jrNQ0JGaQLqykLQCSX7tz2U9t63AsmLSa1nVFTGm/HRFBkoTyMqeS0c41optjfXXv/4VSCzbqsDz7W9/G4C//OUvQBIxOXbsWACOPvroku83kBqAsJlzabbffnsgsadI4j/4YKFMhTSFRmw4Qr8FxVTIRnDssccCiT1C52lu//M//xNINLlqZcI7FdcEHKfL6UhNIL03U7y3orzkN9f+T/t2rdq2AUg9KHdAmogyFCVBtB+XtJLG0EhuvJU6kvRCEYTar06YMKFkDPp8VkPMRuvRNYKNl0+jxi3af6tpqeI7Zs+eDSQajG0EUgvSKhTZKWv/KacUquFZ7UI2H1un0ZYHrzd2Ia+4JuA4XU5HagLpfW263iAkkuLpp58GktVcufxZfvJaVnNFmMmyrc+o2Ygkv60oZH35tSAftLwbsp7ruPbKGoOVlJL01pfdDt+21UIgkaqK/lSWpHIeZLFX6/Jmxq24AGmFymC00abCalHVtKtOxzUBx+lyOlITSO9ntZe0zSaVTajjkuKN5PQL+ZVl7ddeUz0AsiLQGtEEhLQM2ThUEclqNDY/3UpOW3XGSr80rbYX6J6V2mUNHz4cgD/+8RgBhHkAABJ9SURBVI9AMpeKHLQNVetBLdGzvDU2OtP+JjRXtlKSbQme/mwnaQmuCThOl+OLgON0OR25HUiTDhyCRHVTWqiQe68V3XilTsoYpwAluSeldsp92UjaslAYtFTOrMIkVlWVOm1VWTvG9OfaqcKqHLm2XDZJp96w4XSQmFy4el42YMq6BO29NAZtSWxx2zSNBDO1G9cEHKfL6ShNoJxrRo01JdnkIlOijVZ1aQIyENZ7z/R9lYQkCaHwYf3VPVXIo5Y+9lkoqUXuLaUGv/vuuyXjyzL8aV5kMLWSNp3Uk2VUHAhUAl1/VVxEgTpZTWqzkMYDyZwJW4JOEr6cdgTJb8pqYTqeHlM9JeTygmsCjtPldJQmUA5JZVvoQ5JTKA243pW63D7ZhgFbaSxJ2ooCHlmltK+66ioAtttuu5J7WheVbYpqXW3tSChKY5u8yFUo16CVzo0UFbEFRqdOnQok5cKksWXZBDQGG/5cbu46MZDINQHH6XI6ShMot7oqeCZL0mlvbPfxzaDUUqtVSGJon91ICrFFociyZcgT8bvf/Q5Ivu+4cYVG0PJE6Hvq81mBS+mgoXpLeLUC+0xVHvziiy8GkvGX239XIi399W89H4WUH3jggQBMnDgRgI022qjsmBSarrmTVmK9BdA38KgTcE3AcbqczlmuMtDqrD2limpY326jUrmcd0BSVRJCYcN29W+kwKjFFtqUpNe4fv/73wNw/fXXA333qfIuSMqdeOKJAHz/+98ve/5AY6WuWq3re8vfb20c1UjHZtg4Dc2dGpQeeuihQKLB2QImii1RodIf//jHQGLzKZcY1Um4JuA4XU7nLVsGrdKyDSjCzjawzCowWo205JGEkJSSRiCfvd0PNlJMRGj8uoZSbe+++26gbzKO7BOSSjaFWglI0gTkR//Rj37U554DiZXsivvYdtttAbj11luBxDZQq9U9fZ5KmD366KMl50hL0rVtiTN73oUXXggkSV1qZJqW/llt2fOMawKO0+U0tVyFECYAPwIiMBsYD6wKXAesAMwCxsYYP21ynEDfqDhIJJ2ksvXTaj9YrhV3LZRLq5UdQte25+i4cgcaQePX91M5MbUkt/HrNldAKOLOFi4966yzANh11117z1WDk4HE5gZonIp/uP3224HkezXiudhzzz0BuOKKK4BkTmzjmnK/r/Q9pX3J/qLCLgcffHDvuZ2kAYiGNYEQwurACUBPjHEzYFHgQOAs4LwY43rAe8DhrRio4zj9Q7PL1mLAkiGEz4ClgAXASEBL45XAz4FLmrwPUD6jTKu29s42Jl4W/HQ783oody9JEEl6K1n010aqNcN3v/tdINmXymqetY+3Fm7r29a+Vt4FSBqUWKxktE1ChZXm9WAlvKTsGWecASRxAlneAVv6K82IESOAJAZB5ds1JxqvbALWS6DXtk262qofcMABvceyNBY7PmuzaicNjyDG+CpwDvAyhf/5P6Cg/r8fY9RszQfK+uZCCEeGEGaGEGaqaq/jOANPw5pACGE5YAwwBHgfuAHYs9bPxxinAFMAenp6ajJLl4vLtpqARZqAvAj1xnanV2orVVW+XJJR58pT0UzEoJV4l19+OZBkKtroPttcRNZ/Wb6lASjyUNe57777eu+hsuVWOlk7g65tJaPN9Gsmfl5xDVtssQWQlB7PKlFmsyfTe/Np06YBSWszu8fX97At2jRnei0vge7x+OOPA0m9Akh+h/a52OdTb9xDf9KMLjIaeDHG+FaM8TPgRmA4sGwIQU9gDeDVJsfoOE4/0oxN4GVgWAhhKeBjYBQwE7gT2I+Ch2AccHOzgxSVJIus/1rVda6ksazs9Uqp9B7TShmt+lZSylZgV/t69n8698knnwTgmmuuARIprL3yHnvsASSS3TbMkBScPHkykJQw1/WVtw9JjIX1pOhc2TgkzWzuRCv3t3peal1+//33A4k0TtcLgL577HQWqTwh8gIoWlI2EM2JtCbbHv2yyy4D4LXXXgOS563Wd8pFgKSEurB2Ev0+81SBqBmbwIPAVOARCu7BRSio95OAiSGE5yi4CS9rwTgdx+knmvIOxBhPB043h18Atmvmuo2giEDtebXSyivQiqo5VntYf/31gWRvKQkhTaBSie00lbSTG264AUjacm2++eYAjB8/HsiuXygJtNNOOwGw2267AYlPW/kOko6QrQkIaReSZunPpu/ZSo1Amo4s8ZpTWyFKcy8tZfr06b3vSaJLg1Mj0o033rjkGrIBiGHDhgGw7777Akmbd2lP0oSkIaSxtgAbTarvMZDt4LJov3/CcZy20nnhTZTP7NMeUticflsdppEKNXbVludB45F1Wfe0NoF6rOXa86oRqa5x1FFHAYkGIGmse1sJo7Gpmu8+++wDJNFzaWlu99lCcykpq+9tNZ3+2OfKt6+MTNUHlFYibDbkXXfd1ftvaT37778/kDRBtc1NbfUizbnqR5x00kklf1XbQdcvh63gZONYZH9oJ64JOE6Xs9BoApJ0iuuWVJOtoBVSymoRPT09JffUntJmLFbTAMq9r8acsgWouemmm24K9N1rWk1I71spvuOOOwKJt6EWTUB584pWlPRSZeBK36NRNBZ5YDReRTpuvfXWQHaVZeVYQKKxKHJQ51o7kT6bpbnpnvb8cvNmf28nnHACAIcddhiQPA9lh7YT1wQcp8vxRcBxupyO2g5USrqQy2jkyJElx60hpl73VVqts2qiVPDRo0eX/axU7aymFpV4+eWXgSToRa7OddZZp2QMtpiINV5alVZNWHS8XJFMi1RXueuE3XK00t1lk3nkjlUYsQ1R1nNV4I8KvaTHZUPL7dzY8dv5kOtX2yMFaNWCtmELVQKR4zgLBx2lCYj0Cq0V1YZlaoW1hrEsiZlFWlrYAh56bUOVbWCIDSuuBaUKS5tQ0RSFtoqshp1ZrlBpTOWMX1kt2mwask2O6Y+AFxtAJeOePW6luQKe0m47fdYWfs0yZFb7jWjurKaXxs5RlibaTPp1q3BNwHG6nI7SBLJW/zQ2aMSusK1YcbOKbGRR7Z7lwoa1p1VAS1Ybrqy9ZZaGIAmp66abkVRr0TaQzTY1Z/U+L0nndAhw1rWsG69aclm5a0NiZymHLUSTR1wTcJwup6M0gW7C7oW115W3QJ6JrD1mVkux119/HeibyAJ9W5R1IuU8HArmsSG6dp+epSloLhWopAY3sqGoiEyn4pqA43Q5rgnkFGvFl/9bklxxA1bySapZm4CkmtJqlYCT3s82Wow1T0iap1OspQEoFFuxJDapx5YTs6jAi+wpCuVWw5ROxTUBx+lyXBPIKZLKtnCoJLkadwprA5BUk89bXoEZM2aUnK8IROgbg9CJaH+etoVo76/0YrVes9F7WdGX0hSU1i3NQpGDSjXuVFwTcJwuxzWBHFDOL61y5trbKoJQRS/HjBkDJJLPprXaxie//vWvgSQnQV4BNevsdGwb8bR9QyXBVV5dacb2u9vITyENQkVbNbcbbrghUGpXqTciNQ+4JuA4XY5rAjlFFmdJNpWymjt3LpCU0T7ttNOAZD8vKSWJpDZjU6ZMAZL9rM5T489Oxe7r9b3SRURl1VenK83dueeeC8CQIUOAvvkWanhy5plnAknWoCIHd955Z6BU6jeSJ9JuXBNwnC7HNYEcUK70maL3tt12WwBeeuklIJHkv/nNb4DEW6CGpZJiDzzwAJCU3pYmIUk5dOhQIClX1qlk5ZOk9/sqVy7UkFRzplLiKhD74osvAnDTTTcBSXyBtC0VWlW5sjR5aipSK64JOE6X45pAjihXQFVNQ6ZOnQokUkj7UmkCTzzxRMk1bLyAfODyHqj0uK6X/mwrC4YOFLLsKyciXWFKdhXbgk2eErVoUySg3tccKzJQ7w8fPhxItKl0Y1bXBBzH6ThcE8gBleok7LXXXkDfFt22qpFe2+pG+isptu666wJJU86FBVu/UTUJIYmpkMSXZLft1LJakgt5AY444oiy9+xUXBNwnC5n4VjKFmLkJTj55JMBOProo4GkroCNKLTSyTZLnTRpEpBEJKb92p0U5VYPat2myL/nn38eSOZOdhLNoTwo0hQ++ugjIHkGo0aNAjrbhpLGNQHH6XJCHqyZPT09cebMme0eRi6xFW0vuOACAM455xwgqUVoKw1JOml/+4tf/AKA448/vuo9O12yQWmdBRs7ceSRRwLw3HPPAYmNwNpVVHNB9hNFGnZqJaEQwqwYY4897pqA43Q5VReBEMJvQwhvhhCeTB1bPoTw1xDCs8W/yxWPhxDCBSGE50IIT4QQtu7PwTuO0zxVtwMhhJ2Aj4D/iTFuVjx2NvBujPHMEMIpwHIxxkkhhL2A44G9gO2B82OMVXNVfTvQFz0Xm5Ai1fZvf/sbkCQGKTxY72+22WYATJgwAUiCjqTy2gYp5e6xsCADn+ZShsFLL70UgFtuuQVIDINKQz7xxBMBGDt2LJAEVlVrgJJXGt4OxBjvBt41h8cAVxb/fSWwb+r4/8QCM4BlQwir4jhObqnJMBhCWBu4NaUJvB9jXLb47wC8F2NcNoRwK3BmjPHe4nvTgEkxxj5iPoRwJHAkwODBg7dRgoxTwEobSTNJcIUBy3BoG3jqczIoZkmrcga0hYFypcdtazAbUm1Drm1JcvtMOm2++s0wGAszU7eLIcY4JcbYE2PsUbdXx3EGnkaDhd4IIawaY1xQVPffLB5/FVgzdd4axWNOg2RJK6sBKCxYoa5W8ms/rL/lzltYgl+gVEprboS0BNvkVGiObPl2nWfLuHf6fDWqCdwCjCv+exxwc+r4oUUvwTDggxjjgibH6DhOP1JVEwghXAvsAqwYQpgPnA6cCVwfQjgceAnYv3j6bRQ8A88B/wLG98OYuwJJF1sGW+i4tfJbG4KQNJMGUK6Rabl25Z1KJVuHXluJb1ut2ySsrHZlnU7VRSDGeFDGW6PKnBuBY5sdlOM4A4cnEOUUu0+10kxSzPqqpQFkNdeUVNP7aY1hYZJwlTQcK/Gz2rvb8+31Os07kMXC8S0cx2kY1wRySrV9eVZBi6zjWddbWApjVCJLwme9tsft+wuLBiAWrm/jOE7d5CKVOITwFvBP4O12j6UGViT/4/Qxto5OGGetY1wrxtgnMi8XiwBACGFmuZDGvNEJ4/Qxto5OGGezY/TtgON0Ob4IOE6Xk6dFYEq7B1AjnTBOH2Pr6IRxNjXG3NgEHMdpD3nSBBzHaQO+CDhOl5OLRSCEsGcI4eligdJT2j0egBDCmiGEO0MIc0IIT4UQTiweL1tktc1jXTSE8GixshMhhCEhhAeL8/m/IYTFczDGZUMIU0MIfw8hzA0hfDNvcxlCmFB81k+GEK4NISyRh7ns72K/bV8EQgiLAhcB3wI2AQ4KIWzS3lEB8DnwkxjjJsAw4NjiuE4BpsUY1wemFV+3mxOBuanXZwHnxRjXA94DDm/LqEo5H/hTjHEjYEsK483NXIYQVgdOAHqKZfQWBQ4kH3N5BbCnOZY1d98C1i/+dyRwSdWrxxjb+h/wTeDPqdenAqe2e1xlxnkzsBvwNLBq8diqwNNtHtcaxR/BSOBWIFCIHlus3Py2aYzLAC9SNESnjudmLoHVgVeA5Snk1NwK7JGXuQTWBp6sNnfAZOCgcudl/dd2TYBk8sX84rHcUCy0OhR4EFglJtWSXgdWadOwxH8DJwOqorEC8H6MUTnCeZjPIcBbwOXFbctvQghfI0dzGWN8FTgHeBlYAHwAzCJ/cymy5q7u/5/ysAjkmhDCIOD/gJNijP9IvxcLS23bfKwhhH2AN2OMs9o1hhpZDNgauCTGOJRCnkiJ6p+DuVyOQsn8IcBqwNfoq4LnkmbnLg+LQG6Lk4YQvkJhAbg6xnhj8fAb6qVgiqy2g+HAf4QQ5gHXUdgSnE+h34NyhPMwn/OB+THGB4uvp1JYFPI0l6OBF2OMb8UYPwNupDC/eZtLkTV3df//lIdF4GFg/aIVdnEKxphb2jwm9VO4DJgbY/yv1FtZRVYHnBjjqTHGNWKMa1OYtztijIcAdwL7FU9r6xgBYoyvA6+EEDYsHhoFzCFHc0lhGzAshLBU8dlrjLmayxStK/bbLkOMMXrsBTwDPA+c1u7xFMc0goKK9QTwWPG/vSjsuacBzwJ/A5Zv91iL492FQoMYgHWAhygUfL0B+GoOxrcVMLM4n78HlsvbXAK/AP4OPAn8DvhqHuYSuJaCneIzClrV4VlzR8EwfFHx/6XZFLwdFa/vYcOO0+XkYTvgOE4b8UXAcbocXwQcp8vxRcBxuhxfBByny/FFwHG6HF8EHKfL+f91mXGepVGEBwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "label = rev_conv_label(y[0,0])\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(pil_im, interpolation='nearest', cmap=cm.gray)\n",
        "ax.text(5, 5, label , bbox={'facecolor': 'white', 'pad': 10})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BWjB_Io5wIHe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}